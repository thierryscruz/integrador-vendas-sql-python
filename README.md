# üöÄ Data Sentinel

**Data Sentinel** √© um integrador de vendas de alta performance que automatiza a ingest√£o de dados de arquivos CSV para um banco de dados relacional.

A principal filosofia deste projeto √© a **segrega√ß√£o de responsabilidades**:
- **Python**: Atua como orquestrador e ponte de leitura (I/O).
- **SQL (Microsoft SQL Server)**: Det√©m a l√≥gica de neg√≥cio pesada, valida√ß√£o de dados e c√°lculos financeiros via Stored Procedures e Triggers (T-SQL) para garantir atomicidade e consist√™ncia.

> "Neste projeto, utilizei Python para a automa√ß√£o do fluxo e foquei a l√≥gica de neg√≥cio pesada em SQL (Triggers/Procedures) para garantir integridade e performance."

---

## üõ†Ô∏è Tecnologias Utilizadas

- **Banco de Dados**: Microsoft SQL Server (T-SQL, Stored Procedures, Triggers)
- **Backend/Scripting**: Python 3.10+
- **Bibliotecas**: `pandas` (Manipula√ß√£o de Dados), `pyodbc` (Driver ODBC para SQL Server)
- **Analytics**: Microsoft Power BI (Dashboard Interativo)

---

## üèóÔ∏è Arquitetura do Projeto

### 1. O Cora√ß√£o (SQL Avan√ßado)
A intelig√™ncia do sistema reside no banco de dados.
- **Tabela `vendas`**: Armazena o hist√≥rico com integridade tipada (`IDENTITY` para IDs).
- **Stored Procedure `sp_processar_venda`**: Recebe dados brutos da aplica√ß√£o, valida regras de neg√≥cio (ex: valores negativos) e insere apenas dados limpos.
- **Trigger `tg_calcular_comissao`**: Dispara automaticamente **AFTER INSERT**. Calcula 10% de comiss√£o para cada venda registrada, cruzando com a tabela virtual `inserted`.

### 2. A Ponte (Python)
O script `app.py` √© leve e focado em efici√™ncia de I/O.
- L√™ arquivos `.csv` em lote usando a performance do C-engine do Pandas.
- Conecta ao PostgreSQL de forma segura.
- Invoca a Procedure para cada registro, delegando o processamento para o motor do banco.

---

## üìã Como Executar

### Pr√©-requisitos
- Python instalado.
- Servidor PostgreSQL rodando.

### Passo 1: Configurar Banco de Dados
Execute os scripts SQL na ordem abaixo no seu client SQL (SSMS, Azure Data Studio):
```sql
-- 1. Cria a estrutura (Tabela, Procedure e Trigger)
-- Execute o conte√∫do de: sql/create.sql

-- 2. (Opcional) Popula o banco com dados iniciais
-- Execute o conte√∫do de: sql/baseinic.sql
```

### Passo 2: Instalar Depend√™ncias
```bash
cd src
pip install -r requirements.txt
```

### Passo 3: Configurar Ambiente
Crie um arquivo `.env` na pasta `src/` com suas credenciais:
```ini
DB_SERVER=SEU_SERVIDOR
DB_NAME=DataSentinelDB
DB_USER=sa
DB_PASS=sua_senha
```

### Passo 4: Rodar a Integra√ß√£o
```bash
python app.py
```

---

## üìä Dashboard Interativo (Power BI)
Este projeto foi desenhado para integra√ß√£o nativa com o **Power BI**.

1. Abra o Power BI Desktop.
2. Selecione **Obter Dados** > **SQL Server**.
3. Insira o servidor (`localhost` ou seu servidor) e o banco `DataSentinelDB`.
4. Use o modo **DirectQuery** para ver os dados entrando em tempo real conforme o script Python roda.

Sugest√£o de Visuais:
- **Cart√µes**: Total de Vendas, Total de Comiss√µes.
- **Gr√°fico de Barra**: Vendas por Produto.
- **Pizza**: Status dos Pedidos (Confirmado, Pendente, etc).

> **Nota**: Para facilitar a visualiza√ß√£o imediata, o projeto inclui o arquivo de dados `data/dataset_powerbi.csv`. Voc√™ pode carregar este arquivo no Power BI para ver os gr√°ficos populados com os mesmos dados do script de carga inicial, sem precisar configurar a conex√£o com o banco de dados SQL agora.

---

> _Obs: O arquivo `sql/baseinic.sql` cont√©m um script para inser√ß√£o de 100 produtos variados para testes de carga e valida√ß√£o da trigger._
